import streamlit as st
import requests
import base64
import json
import io
from gtts import gTTS
from duckduckgo_search import DDGS
import speech_recognition as sr

# --- ìƒìˆ˜ ---
OLLAMA_HOST = "http://192.168.0.119:11434"  # Ollama ì„œë²„ ì£¼ì†Œë¡œ ë³€ê²½
OLLAMA_MODEL = "llama3.2-vision"
SYSTEM_PROMPT = """
ë‹¹ì‹ ì€ ì „ë¬¸ ë¶„ì„ê°€ì…ë‹ˆë‹¤. ì£¼ì–´ì§„ ì •ë³´ì™€ ì§ˆë¬¸ì„ ë¶„ì„í•˜ì„¸ìš”.
ë‹¤ìŒ í‚¤ë¥¼ ì‚¬ìš©í•˜ì—¬ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µì„ ì œê³µí•˜ì„¸ìš”:

- "probability": "ì˜ˆ" (í•´ì•¼ í•¨/êµ¬ë§¤í•´ì•¼ í•¨) ëŒ€ "ì•„ë‹ˆì˜¤" (í•˜ì§€ ë§ì•„ì•¼ í•¨/êµ¬ë§¤í•˜ì§€ ë§ì•„ì•¼ í•¨)ì˜ ê°€ëŠ¥ì„±ì„ ë‚˜íƒ€ë‚´ëŠ” ë°±ë¶„ìœ¨ (0-100)ì…ë‹ˆë‹¤.
                   ë” ë†’ì€ ë°±ë¶„ìœ¨ì€ "ì˜ˆ"ë¥¼ ì˜ë¯¸í•˜ê³ , ë” ë‚®ì€ ë°±ë¶„ìœ¨ì€ "ì•„ë‹ˆì˜¤"ë¥¼ ì˜ë¯¸í•©ë‹ˆë‹¤.
- "reason": í•´ë‹¹ë˜ëŠ” ê²½ìš° ì¶œì²˜ë¥¼ ì¸ìš©í•˜ì—¬ ë¶„ì„ ë° ì¶”ë¡ ì— ëŒ€í•œ ê°„ê²°í•œ ì„¤ëª….

ì˜ˆì‹œ:
{"probability": 75, "reason": "í˜„ì¬ ì‹œì¥ ë™í–¥ê³¼ ì „ë¬¸ê°€ ì˜ê²¬ì— ë”°ë¥´ë©´, í•´ë‹¹ ì£¼ì‹ì€ ê°•ë ¥í•œ ì„±ì¥ ì ì¬ë ¥ì„ ë³´ì…ë‹ˆë‹¤."}
"""

# --- ë„ìš°ë¯¸ í•¨ìˆ˜ ---

def text_to_speech(text, language="ko"):
    """gTTSë¥¼ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ë¥¼ ìŒì„±ìœ¼ë¡œ ë³€í™˜í•˜ê³  ë°”ì´íŠ¸ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    try:
        tts = gTTS(text=text, lang=language, slow=False)
        buffer = io.BytesIO()
        tts.write_to_fp(buffer)
        buffer.seek(0)
        return buffer.read()
    except Exception as e:
        st.error(f"gTTS ì˜¤ë¥˜: {e}")
        return None

def encode_image(image_bytes):
    """ì´ë¯¸ì§€ ë°”ì´íŠ¸ë¥¼ base64ë¡œ ì¸ì½”ë”©í•©ë‹ˆë‹¤."""
    return base64.b64encode(image_bytes).decode("utf-8")

def perform_ddg_search(query, max_results=3):
    """DuckDuckGo ê²€ìƒ‰ì„ ìˆ˜í–‰í•˜ê³  ì—°ê²°ëœ ê²°ê³¼ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.  ë¹ˆ ì¿¼ë¦¬ ì²˜ë¦¬."""
    if not query:  # ë¹ˆ ì¿¼ë¦¬ í™•ì¸
        return ""
    try:
        with DDGS() as ddgs:
            results = [r["body"] for r in ddgs.text(query, max_results=max_results)]
        return "\n\n".join(results)
    except Exception as e:
        st.error(f"DuckDuckGo ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
        return ""

def call_ollama_api(messages, stream=False, format="json"):
    """ì£¼ì–´ì§„ ë©”ì‹œì§€ë¡œ Ollama APIë¥¼ í˜¸ì¶œí•©ë‹ˆë‹¤."""
    data = {
        "model": OLLAMA_MODEL,
        "messages": messages,
        "stream": stream,
        "format": format,
        "options": {
            "temperature": st.session_state.temperature,
            "num_predict": st.session_state.max_tokens,
        }
    }
    try:
        response = requests.post(f"{OLLAMA_HOST}/api/chat", json=data)
        response.raise_for_status()
        return response.json()
    except requests.exceptions.RequestException as e:
        st.error(f"Ollama API ì˜¤ë¥˜: {e}")
        return None

def transcribe_audio(language_code):
    """speech_recognitionì„ ì‚¬ìš©í•˜ì—¬ ë§ˆì´í¬ì—ì„œ ì˜¤ë””ì˜¤ë¥¼ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
    r = sr.Recognizer()
    with sr.Microphone() as source:
        st.toast("ë“£ê³  ìˆìŠµë‹ˆë‹¤...", icon="ğŸ™ï¸")
        audio = r.listen(source, timeout=5, phrase_time_limit=10)
        st.toast("ì²˜ë¦¬ ì¤‘...", icon="â³")
        try:
            text = r.recognize_google(audio, language=language_code)
            return text
        except sr.UnknownValueError:
            st.warning("ìŒì„±ì„ ì´í•´í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return None
        except sr.RequestError as e:
            st.error(f"Google ìŒì„± ì¸ì‹ ì„œë¹„ìŠ¤ì—ì„œ ê²°ê³¼ë¥¼ ìš”ì²­í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")
            return None


# --- ë¶„ì„ í•¨ìˆ˜ ---

def analyze_image(image_data, question, language):
    """Ollamaë¥¼ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ì™€ ì§ˆë¬¸ì„ ë¶„ì„í•˜ê³  í™•ë¥ , ì´ìœ  ë° ì˜¤ë””ì˜¤ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    if question:  # ì§ˆë¬¸ì´ ìˆìœ¼ë©´ DuckDuckGo ê²€ìƒ‰ ìˆ˜í–‰
        search_results = perform_ddg_search(question, max_results=2)
        combined_input = f"{question}\n\nê´€ë ¨ ì •ë³´:\n{search_results}"
    else:  # ì§ˆë¬¸ì´ ì—†ìœ¼ë©´ ì´ë¯¸ì§€ë§Œ ì‚¬ìš©
        combined_input = "ì‚¬ì§„ì— ëŒ€í•´ ë¶„ì„í•´ì£¼ì„¸ìš”."  # ê¸°ë³¸ ë©”ì‹œì§€


    messages = [
        {"role": "system", "content": SYSTEM_PROMPT},
        {"role": "user", "content": combined_input, "images": [image_data]},
    ]
    response_json = call_ollama_api(messages)
    if response_json:
        return process_ollama_response(response_json, language)
    else:
        return None, "ì˜¤ë¥˜: Ollama API í˜¸ì¶œ ì‹¤íŒ¨.", None

def analyze_text(question, language):
    """Ollamaë¥¼ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ ì§ˆë¬¸ì„ ë¶„ì„í•˜ê³  í™•ë¥ , ì´ìœ  ë° ì˜¤ë””ì˜¤ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    search_results = perform_ddg_search(question)
    combined_input = f"{question}\n\nê´€ë ¨ ì •ë³´:\n{search_results}"
    messages = [
        {"role": "system", "content": SYSTEM_PROMPT},
        {"role": "user", "content": combined_input},
    ]
    response_json = call_ollama_api(messages)
    if response_json:
        return process_ollama_response(response_json, language)
    else:
        return None, "ì˜¤ë¥˜: Ollama API í˜¸ì¶œ ì‹¤íŒ¨.", None

def process_ollama_response(response_json, language):
    """Ollama API ì‘ë‹µì„ ì²˜ë¦¬í•˜ê³ , ë°ì´í„°ë¥¼ ì¶”ì¶œí•˜ê³ , TTSë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    try:
        content_str = response_json['message']['content']
        content_json = json.loads(content_str)
        probability = content_json.get("probability", None)
        reason = content_json.get("reason", None)

        if probability is not None and not (0 <= probability <= 100):
            raise ValueError("í™•ë¥ ì´ 0-100 ë²”ìœ„ ë‚´ì— ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.")

        audio_bytes = text_to_speech(reason, language) if reason else None

        return probability, reason, audio_bytes
    except (json.JSONDecodeError, KeyError, ValueError) as e:
        st.error(f"Ollama ì‘ë‹µ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
        return None, "ì˜¤ë¥˜: Ollamaë¡œë¶€í„° ìœ íš¨í•˜ì§€ ì•Šì€ ì‘ë‹µ.", None


# --- Streamlit ì•± ---

st.set_page_config(page_title="í•´ì•¼ í• ê¹Œìš”...?", page_icon="ğŸ¤”", layout="wide")

# --- Custom CSS ---
st.markdown("""
<style>
/* (CSS ìŠ¤íƒ€ì¼ - ì´ì „ê³¼ ë™ì¼) */
/* Main container */
.main {
    padding: 2rem;
    font-family: sans-serif; /* Modern font */
}

/* Title */
.title {
    font-size: 3rem;
    font-weight: bold;
    margin-bottom: 1rem;
    color: #333;  /* Darker title color */
}

/* Subtitle/Description */
.subtitle {
    font-size: 1.25rem;
    color: #555;
    margin-bottom: 2rem;
}

/* Input area */
.stTextInput, .stFileUploader, .stCameraInput, .stRadio {
    margin-bottom: 1rem;
}

/* Buttons */
.stButton>button {
    background-color: #007bff; /* Primary blue color */
    color: white;
    border: none;
    padding: 0.75rem 1.5rem;
    border-radius: 0.5rem; /* Rounded corners */
    font-weight: bold;
    transition: background-color 0.2s ease; /* Smooth hover effect */
}
.stButton>button:hover {
    background-color: #0056b3; /* Darker blue on hover */
}
.stButton>button:focus {
    outline: none;  /* Remove the focus outline */
    box-shadow: 0 0 0 3px rgba(0, 123, 255, 0.25); /* Add a subtle focus ring */
}

/* Radio buttons */
.stRadio > div > label { /* Target radio button labels */
  margin-right: 1rem; /* Add spacing */
  padding: 0.5rem 1rem;
  border-radius: 0.5rem; /* Rounded */
  border: 1px solid #ccc;
  transition: all 0.2s ease;  /* Smooth transition */
}
/* Style the selected radio option */
.stRadio > div > label[data-baseweb="radio"] > div:first-child {
    background-color: #007bff !important;  /* Override to ensure color */
    border-color: #007bff !important;
}
.stRadio > div > label[data-baseweb="radio"] {
    background-color: #f0f2f6;
    border-color: #f0f2f6;
}


/* Result area */
.result-area {
    padding: 1.5rem;
    border-radius: 0.75rem;
    background-color: #f8f9fa; /* Light background */
    border: 1px solid #e9ecef;  /* Subtle border */
}

/* Success/Error messages */
.st-success, .st-error {
    padding: 1rem;
    border-radius: 0.5rem;
    margin-bottom: 1rem;
    font-weight: bold;
    color: white;
    display: flex;
    align-items: center;
}
.st-success {
    background-color: #28a745; /* Green */
}
.st-error {
    background-color: #dc3545; /* Red */
}
.st-success svg, .st-error svg { /* Icons within success/error */
    margin-right: 0.5rem;  /* Space the icon */
    font-size: 1.2em;
}


/* Expander */
.st-expander {
  border: none !important; /* No borders */
}
.st-expanderHeader {
    font-weight: bold;
    background-color: transparent;
    padding: 0.5rem 0;
}
.st-expanderContent {
    padding: 0.5rem 0;
}

/* Gauge/Progress */
.stProgress > div > div > div > div {
    background-color: #007bff; /* Consistent blue */
}

/* Sidebar */
.sidebar .sidebar-content {
    padding: 1rem;
    background-color: #f0f2f6; /* Lighter background */
}
</style>
""", unsafe_allow_html=True)

# --- ì„¸ì…˜ ìƒíƒœ ---
if "language" not in st.session_state:
    st.session_state["language"] = "ko"
if "max_tokens" not in st.session_state:
    st.session_state["max_tokens"] = 256
if "temperature" not in st.session_state:
    st.session_state["temperature"] = 0.7

# --- ì‚¬ì´ë“œë°” ---
with st.sidebar:
    st.header("âš™ï¸ ì„¤ì •")
    st.session_state.language = st.selectbox("ì–¸ì–´", ["ko", "en", "ja", "zh-CN", "fr", "de"], index=0)
    language_code = st.session_state.language.split("-")[0]

    with st.expander("LLM ì„¤ì •"):
        st.session_state.max_tokens = st.slider("ìµœëŒ€ í† í° ìˆ˜", 1, 2048, 256, 1)
        st.session_state.temperature = st.slider("ì˜¨ë„", 0.1, 4.0, 0.7, 0.1)

# --- ë©”ì¸ ì•± ---
st.markdown("<h1 class='title'>í•´ì•¼ í• ê¹Œìš”...? ğŸ¤”</h1>", unsafe_allow_html=True)
st.markdown("<p class='subtitle'>ì§ˆë¬¸ì„ í•˜ê³  í™•ë¥  ê¸°ë°˜ ë¶„ì„ì„ ë°›ìœ¼ì„¸ìš”!</p>", unsafe_allow_html=True)

col1, col2 = st.columns([3, 1])

with col1:
    input_type = st.radio("ì…ë ¥ ìœ í˜•", ["í…ìŠ¤íŠ¸", "ìŒì„±", "ì´ë¯¸ì§€ ì—…ë¡œë“œ", "ì‚¬ì§„ ì´¬ì˜"], horizontal=True)
    question = ""

    if input_type == "í…ìŠ¤íŠ¸":
        question = st.text_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”:", placeholder="ì˜ˆ: ì´ ì£¼ì‹ì„ ì‚¬ì•¼ í• ê¹Œìš”?")

    elif input_type == "ìŒì„±":
        if st.button("ğŸ¤ ì§ˆë¬¸ ë…¹ìŒ"):
            question = transcribe_audio(language_code)
            if question:
                st.write("ë‹¹ì‹ ì˜ ì§ˆë¬¸:", question)

    # ì´ë¯¸ì§€ ì—…ë¡œë“œ ì‹œ í…ìŠ¤íŠ¸ ì§ˆë¬¸ ì…ë ¥ í•„ë“œ ì¶”ê°€
    if input_type == "ì´ë¯¸ì§€ ì—…ë¡œë“œ":
        question = st.text_input("ì§ˆë¬¸ (ì„ íƒ ì‚¬í•­):", placeholder="ì´ë¯¸ì§€ì— ëŒ€í•œ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš” (ì„ íƒ ì‚¬í•­).")
        uploaded_image = st.file_uploader("ì´ë¯¸ì§€ ì—…ë¡œë“œ", type=["jpg", "jpeg", "png"], label_visibility='collapsed')
        camera_image = None  # ì‚¬ì§„ ì´¬ì˜ ì˜µì…˜ ì‚¬ìš© ì•ˆí•¨

    elif input_type == "ì‚¬ì§„ ì´¬ì˜":
         question = st.text_input("ì§ˆë¬¸ (ì„ íƒ ì‚¬í•­):", placeholder="ì‚¬ì§„ì— ëŒ€í•œ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš” (ì„ íƒ ì‚¬í•­).")
         camera_image = st.camera_input("ì‚¬ì§„ ì´¬ì˜", label_visibility="collapsed")
         uploaded_image = None

    else: # Text, Voice
        uploaded_image = None
        camera_image = None


    if st.button("ë¶„ì„", type="primary", use_container_width=True):
        if input_type == "ì´ë¯¸ì§€ ì—…ë¡œë“œ" and not uploaded_image:
             st.warning("ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
        elif input_type == "ì‚¬ì§„ ì´¬ì˜" and not camera_image:
            st.warning("ì‚¬ì§„ì„ ì´¬ì˜í•´ì£¼ì„¸ìš”")
        elif not question and input_type in ("í…ìŠ¤íŠ¸", "ìŒì„±") :  # í…ìŠ¤íŠ¸/ìŒì„±ì¸ë° ì§ˆë¬¸ì´ ì—†ëŠ” ê²½ìš°
            st.warning("ì§ˆë¬¸ì„ ì…ë ¥í•˜ê±°ë‚˜, ìŒì„±ì„ ë…¹ìŒí•´ì£¼ì„¸ìš”.")

        else:
            with st.spinner("ë¶„ì„ ì¤‘..."):
                if input_type in ("í…ìŠ¤íŠ¸", "ìŒì„±") and question:
                    probability, reason, audio = analyze_text(question, st.session_state.language)
                elif input_type == "ì´ë¯¸ì§€ ì—…ë¡œë“œ" and uploaded_image:
                    image_bytes = uploaded_image.getvalue()
                    image_base64 = encode_image(image_bytes)
                    probability, reason, audio = analyze_image(image_base64, question, st.session_state.language)
                elif input_type == "ì‚¬ì§„ ì´¬ì˜" and camera_image:
                    image_bytes = camera_image.getvalue()
                    image_base64 = encode_image(image_bytes)
                    probability, reason, audio = analyze_image(image_base64, question, st.session_state.language)

                else:
                    probability, reason, audio = None, "ì…ë ¥ì´ ì œê³µë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.", None

                with col2:
                    if probability is not None and reason:
                        st.subheader("ë¶„ì„ ê²°ê³¼")
                        with st.container(border=True):

                            if probability >= 50:
                                st.success(f"âœ… ì˜ˆ! ({probability}%)")
                            else:
                                st.error(f"âŒ ì•„ë‹ˆì˜¤! ({probability}%)")
                            st.progress(probability / 100.0)

                            with st.expander("ì´ìœ ", expanded=True):
                                st.markdown(reason)
                            if audio:
                                st.audio(audio, format="audio/mp3")
                    elif reason:
                        st.error(reason)