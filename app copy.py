import streamlit as st
import requests
import base64
import json
import io
import torch
import torchaudio
from zonos.model import Zonos

# Zonos ëª¨ë¸ ë¡œë“œ (ì˜¤ë¥˜ ì²˜ë¦¬)
try:
    zonos_model = Zonos.from_pretrained("Zyphra/Zonos-v0.1-hybrid", device="cuda")
    zonos_model.eval()
except Exception as e:
    print(f"Error loading Zonos model: {e}")
    zonos_model = None

# Ollama API ì„¤ì •
OLLAMA_HOST = "http://192.168.0.119:11434"  # Ollama ì„œë²„ ì£¼ì†Œ
OLLAMA_MODEL = "llama3.2-vision"  # ì‚¬ìš©í•  ëª¨ë¸


# ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
SYSTEM_PROMPT = """
You are an expert analyst. Analyze the given image and question.
Provide a response in JSON format with the following keys:

- "probability":  A percentage (0-100) indicating the likelihood of "yes" (should do/buy) vs. "no" (should not do/buy).
                    Higher percentage means "yes", lower percentage means "no".
- "reason": A concise explanation of your analysis and reasoning.

Example:
{"probability": 75, "reason": "The stock chart shows an upward trend with increasing volume, indicating a good buying opportunity."}
"""
def text_to_speech(text, language="en-us", speed=1.0, pitch_variation=0.5, max_frequency=44000, audio_quality=0.7, emotion="neutral"):
    """Zonos TTSë¥¼ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ë¥¼ ìŒì„±ìœ¼ë¡œ ë³€í™˜í•˜ê³ , bytes í˜•íƒœë¡œ ë°˜í™˜."""
    if zonos_model is None:
        return None

    with torch.no_grad():
        try:
            dummy_wav = torch.randn(1, 16000)
            dummy_sr = 16000
            dummy_speaker = zonos_model.make_speaker_embedding(dummy_wav, dummy_sr)
            cond_dict = make_cond_dict(
                text=text,
                speaker=dummy_speaker,
                language=language,
                speed=speed,
                pitch_variation = pitch_variation,
                max_frequency=max_frequency,
                audio_quality=audio_quality,
                emotion=emotion
            )
            conditioning = zonos_model.prepare_conditioning(cond_dict)
            codes = zonos_model.generate(conditioning)
            wavs = zonos_model.autoencoder.decode(codes).cpu()

            # BytesIOë¥¼ ì‚¬ìš©í•˜ì—¬ ì˜¤ë””ì˜¤ ë°ì´í„°ë¥¼ bytes í˜•íƒœë¡œ ë³€í™˜
            buffer = io.BytesIO()
            torchaudio.save(buffer, wavs[0], zonos_model.autoencoder.sampling_rate, format="wav")
            return buffer.getvalue()

        except Exception as e:
            print(f"TTS Error: {e}")
            return None


def analyze_image(image_data, question, language, speed, pitch_variation, max_frequency, audio_quality, emotion, max_tokens, temperature, top_p):
    """Ollama APIë¥¼ í˜¸ì¶œí•˜ì—¬ ì´ë¯¸ì§€ì™€ ì§ˆë¬¸ì„ ë¶„ì„í•˜ê³ , JSON ì‘ë‹µì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
    # print(f"analyze_image : {question}")
    messages = [
        {"role": "system", "content": SYSTEM_PROMPT},
        {"role": "user", "content": question, "images": [image_data]},
    ]

    data = {
        "model": OLLAMA_MODEL,
        "messages": messages,
        "stream": False,  # JSON ì‘ë‹µ ì „ì²´ë¥¼ ë°›ê¸° ìœ„í•´ False
        "format": "json",  # JSON í˜•ì‹ ì§€ì •
        "options": {
            "temperature": temperature,
            "num_predict": max_tokens,
        }
    }

    try:
        response = requests.post(f"{OLLAMA_HOST}/api/chat", json=data)
        response.raise_for_status()
        response_json = response.json()
        # print("response_json",response_json) # ë””ë²„ê¹…

        content_str = response_json['message']['content']
        # print("content_str:", content_str)

        # JSON ë¬¸ìì—´ íŒŒì‹±
        try:
            content_json = json.loads(content_str)
            probability = content_json.get("probability", None)
            reason = content_json.get("reason", None)

            #Zonos TTS
            audio_output = None
            audio_bytes = text_to_speech(reason, language,speed, pitch_variation,max_frequency,audio_quality, emotion) # type: ignore
            if audio_bytes:
                audio_output = audio_bytes  # ì˜¤ë””ì˜¤ ë°ì´í„° ì €ì¥

            return probability, reason, audio_output
        except json.JSONDecodeError as e:
            print(f"JSON parsing error: {e}")
            return None, "Error: Invalid JSON response from Ollama.", None

    except requests.exceptions.RequestException as e:
        print(f"Ollama API request failed: {e}")
        return None, "Error: Could not communicate with Ollama API.", None


# Streamlit ì•± ì„¤ì •
st.set_page_config(page_title="Should I...?", page_icon="ğŸ¤”")
st.title("Should I...? ğŸ¤”")
st.write("Upload an image and ask a question to get a probability-based analysis!")

#ì‚¬ì´ë“œë°”
with st.sidebar:
    st.header("Settings")
    language = st.selectbox("Language", ["en-us", "ja-jp", "zh-cn", "fr-fr", "de-de"], index=0)
    speed = st.slider("Speed", 0.5, 2.0, 1.0, 0.1)
    pitch_variation = st.slider("Pitch Variation", 0.0, 1.0, 0.5, 0.1)
    max_frequency = st.slider("Max Frequency", 5000, 44000, 44000, 1000)
    audio_quality = st.slider("Audio Quality", 0.0, 1.0, 0.7, 0.05)
    emotion = st.selectbox("Emotion", ["neutral", "happy", "sad", "angry", "fearful"], index=0)

    st.header("LLM Settings")
    max_tokens = st.slider("Max Tokens", 1, 2048, 256, 1)
    temperature = st.slider("Temperature", 0.1, 4.0, 0.7, 0.1)
    top_p = st.slider("Top P", 0.1, 1.0, 0.9, 0.05)



# ì´ë¯¸ì§€ ì—…ë¡œë“œ
uploaded_image = st.file_uploader("Upload an image", type=["jpg", "jpeg", "png"])

# ì§ˆë¬¸ ì…ë ¥
question = st.text_input("Ask a question (e.g., Should I buy this stock? Should I buy this product?)")

if uploaded_image and question:
    # ì´ë¯¸ì§€ë¥¼ base64ë¡œ ì¸ì½”ë”©
    image_bytes = uploaded_image.getvalue()
    image_base64 = base64.b64encode(image_bytes).decode("utf-8")

    # Ollama API í˜¸ì¶œ
    probability, reason, audio = analyze_image(image_base64, question, language, speed, pitch_variation, max_frequency, audio_quality, emotion, max_tokens, temperature, top_p)


    if probability is not None and reason: # type: ignore
        # ë©”íŠ¸ë¡œë†ˆ ìŠ¤íƒ€ì¼ ê²Œì´ì§€ í‘œì‹œ
        if probability >= 50:
            color = "green"
            emoji = "âœ…"  # ê¸ì • ì´ëª¨ì§€
        else:
            color = "red"
            emoji = "âŒ"  # ë¶€ì • ì´ëª¨ì§€

        st.progress(probability / 100.0, text=f"{emoji} Probability: {probability}%")

        # ë¶„ì„ ì´ìœ  í‘œì‹œ
        st.markdown(f"**Reason:** {reason}")

        if audio:
            st.audio(audio, format="audio/wav")


    else:
        st.error(reason)  # ì˜¤ë¥˜ ë©”ì‹œì§€ í‘œì‹œ

elif uploaded_image or question:
    # ì´ë¯¸ì§€ë§Œ ì—…ë¡œë“œí•˜ê±°ë‚˜, ì§ˆë¬¸ë§Œ ì…ë ¥í–ˆì„ë•Œ
    st.warning("ì´ë¯¸ì§€ì™€ ì§ˆë¬¸ì„ *ëª¨ë‘* ì…ë ¥í•´ì£¼ì„¸ìš”(Please enter *both* an image and a question.)")